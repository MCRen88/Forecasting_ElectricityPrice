{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"10\"> **Spanish Electricity Pool Forecasting: Neural Network Model Building** <font size=\"10\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook goal is to build a Machine Learning model that forecast the next period spot price. \n",
    "\n",
    "Remember that a model is just a representation of an actual process that generates the output. This representation tries to accomplish two items:\n",
    "1. Capture every input feature that affects this process.\n",
    "2. Quantify (set up rules or a formula coeffcients) the relationship between these input features and the outcome.\n",
    "\n",
    "$$ \\text{Target: } Y $$\n",
    "\n",
    "$$ \\text{Actual feature space: } X={X_{1}, X_{2}, ..., X_{m}, X_{m+1}, X_{X_m+2}, X_{X_m+m'}} $$\n",
    "\n",
    "$$ \\text{Actual process: } Y = H(X) +\\epsilon $$\n",
    "\n",
    "Where $\\epsilon$ stands for the random nature of the process, errors in data measuring or missed parts of the actual feature space.\n",
    "\n",
    "$$ \\text{Predicted target: } \\hat{Y} \\simeq Y$$\n",
    "\n",
    "$$ \\text{Input feature space: } X={X_{1}, X_{2}, ..., X_{m}} $$\n",
    "\n",
    "$$ \\text{Approximation function (Model): } \\hat{Y} = F(X_{1}, X_{2}, ..., X_{m}) $$\n",
    "\n",
    "\n",
    "\n",
    "Regaring step 1:\n",
    "Sometimes not every input feature that take part in the actual process is known or data is not available, so even if actual process behavior is known, our representation will be an approximation.\n",
    "\n",
    "Therefore the first step is to collecta data, with the objective of arranging a set of input features (variables) that may affect our ouput variable (target). In EDA step, some sort of feature selection can be done, but for the sake of argument, let's assume it does not.\n",
    "\n",
    "Regarding step 2:\n",
    "To sum up, a model is approximation function that maps from features inputs X (dealt with in step 1) to a target Y. There are many algorithms that will aproximate this function, once  one of them is chosen, the next step is Model  building. It is a complex task fulfilled in two overlapping steps:\n",
    "* Hyperparameter tunning: It is the process of deciding model structure, that will determine model ability to fit data current data and generalize to future data.\n",
    "* Model training: For a particular model structure, come up with concrete instance (fitted coefficients or rules) fitted to data, that can yield predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit, ParameterGrid\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "\n",
    "import mle_utils.predictions as mle_preds\n",
    "import mle_utils.timeseries_cv as mle_tscv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "sns.set(\n",
    "    rc=config.set_plot_features(), style=\"darkgrid\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './data/'\n",
    "DEPLOY_PATH = \"./models/\"\n",
    "DEPLOY_MODEL_NAME = 'MLP_V01_2019_31_05.sav'\n",
    "infile = 'data_spot_price_forecasting.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(PATH + infile, parse_dates=['date'], index_col=['date'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in list(data.columns) if \"feat_\" in x]\n",
    "#Multiperiod forecasting\n",
    "targets = [x for x in list(data.columns) if \"target_\" in x]\n",
    "#Single period forecasting\n",
    "target = targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As evaluation strategy, two approach are followed:\n",
    "* Evaluate in a test dataset, holding out 2019 data\n",
    "* Compute Cross Validation mean error on train data, up to year 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_yr = 2019\n",
    "X_train = data[:str(split_yr-1)][features]\n",
    "y_train = data[:str(split_yr-1)][target]\n",
    "\n",
    "X_test = data[str(split_yr):][features]\n",
    "y_test = data[str(split_yr):][target]\n",
    "\n",
    "idx_train = X_train.index.values\n",
    "idx_test = X_test.index.values\n",
    "nobs, p = X_train.shape\n",
    "\n",
    "preds_df = data[[target]].copy()\n",
    "preds_df[\"flg_isTrain\"] = 1\n",
    "preds_df.loc[idx_test, \"flg_isTrain\"] = 0\n",
    "\n",
    "\n",
    "print(\"Total number of observations: \", nobs)\n",
    "print(\"Train: {}{}, \\nTest: {}{}\".format(X_train.shape, y_train.shape,\n",
    "                                              X_test.shape, y_test.shape))\n",
    "\n",
    "X_train[\"feat_spot_price_std\"].plot(label=\"train\", figsize=(12, 8))\n",
    "X_test[\"feat_spot_price_std\"].plot(label=\"test\")\n",
    "plt.title(\"Train/Test split\")\n",
    "plt.ylabel(\"Spot price (â‚¬/MWh)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model: Linear Regresion\n",
    "The first candidate model that every Data Scientist MUST try is a linear one, it is an easy way to stablish a baseline forecasting and understand variance and noise in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train, RMSE_train, MAPE_train, R2_train = mle_preds.pred_and_score_model(model=lr, X=X_train, y=y_train, label=\"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test, RMSE_test, MAPE_test, R2_test = mle_preds.pred_and_score_model(model=lr, X=X_test, y=y_test, label=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a forecasting problem, it is important to carry out a systematic residual diagnosis analysis. There are several ways, but the main goal are:\n",
    "* Compare forecasted vs actual values to visually assess model performance\n",
    "* Visualize residuals distribution to check normality\n",
    "* Assess whether residuals variance is constant over time and over actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"p_lr\"] = np.concatenate((p_train, p_test),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mle_preds.plot_predictions(y=y_test, p=p_test, time_index=idx_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model performance is quite good it is able to capture properly trend and seasionality, RMSE is quite low and MAPE is over 5%, decent scores for a linear model, it proves that even a simple model with may features and data enough may be a good one.\n",
    "Residual analysis shows that there is room for improvements, as conditions previously stated are not strictly fulfilled.\n",
    "\n",
    "Let's try a cross-validation error assessment to perform a hollistic model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular cross-validation strategys are not appropiate to time series data, it is better to use a time series split, so validation data is always ahead train data. In scikit-learn, validation data size is hold fixed and train data grows, therefore first folds may not have data enough to train a double seasonal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_splits= 10\n",
    "splits = TimeSeriesSplit(n_splits=k_splits, max_train_size=5*365)\n",
    "\n",
    "fig, axs = plt.subplots(k_splits,1, sharex=True, figsize=(12,8))\n",
    "i=0\n",
    "for train_index, val_index in splits.split(X_train):    \n",
    "    y_train[train_index].plot(ax=axs[i], label=\"Train folds\")\n",
    "    y_train[val_index].plot(ax=axs[i], label=\"Validation fold\")\n",
    "    axs[i].set_title(\"Train {}, Test: {}\".format( len(train_index), len(val_index)))\n",
    "    if i==0:\n",
    "        axs[i].legend()\n",
    "    i+=1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model CV Error assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cv_mean_train_score, lr_cv_mean_val_score, lr_kfold_train_scores, lr_kfold_val_scores =\\\n",
    "    mle_tscv.time_series_CV(model=lr, cv_splits=splits, min_train_len=2*365, X=X_train, y=y_train, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation mean RMSE and test RMSE are quit similar, so the former can be a good proxy for the later "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression: Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to use a more advanced model to forecast, as linear regression suffers from multicollinearity and some feature are highly correlated, the next model to try is a regularized regression. Let's try Lasso Regression that may yield an sparse model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_lasso = Lasso(random_state=123)\n",
    "\n",
    "param_lasso_dict = {'alpha':[0.001, 0.01, 0.1, 1, 10, 100]} \n",
    "param_lasso_grid = ParameterGrid(param_lasso_dict)\n",
    "\n",
    "lr_lasso, lasso_best_model_idx, lasso_train_cv_score, lasso_val_cv_score, lasso_cv_report_df =\\\n",
    "    mle_tscv.time_series_CV_grid_search(model=lr_lasso,param_grid=param_lasso_grid,\n",
    "                                        cv_splits=splits, min_train_len=2*365,\n",
    "                                        X=X_train,\n",
    "                                        y=y_train.values,\n",
    "                                        refit=True, dev=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coefs = lr_lasso.coef_\n",
    "lasso_coefs_df = pd.DataFrame(index=features, data=lasso_coefs, columns=[\"coefficients\"]).sort_values(by=\"coefficients\")\n",
    "print(\"Zeroed coefficients: \", lasso_coefs_df[lasso_coefs_df[\"coefficients\"]==0].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(16,8))\n",
    "\n",
    "lasso_coefs_df[lasso_coefs_df[\"coefficients\"]>0].plot(kind=\"barh\", ax=axs[0])\n",
    "lasso_coefs_df[lasso_coefs_df[\"coefficients\"]<0].plot(kind=\"barh\", color =\"lightcoral\", ax=axs[2])\n",
    "axs[2].set_xlim(0, lasso_coefs_df[\"coefficients\"].head().values[0]*1.1)\n",
    "plt.suptitle(\"Feature importance\")\n",
    "fig.delaxes(axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"p_lasso\"] = np.concatenate((lr_lasso.predict(X_train), lr_lasso.predict(X_test)),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network: Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Nets are parametric models like regressions, that can model any relationship. In theory, the can find complex relationships among features by adding more neurons over more layers. As there are may features and overfitting risk is high, let's try a small NN with only one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPRegressor(activation ='relu', early_stopping=False, \n",
    "                    solver='adam', beta_1=0.9, beta_2=0.999, epsilon=1e-8,\n",
    "                    random_state=123, verbose=False)\n",
    "\n",
    "param_mlp_dict = {'hidden_layer_sizes':[(2), (3), (5)],\n",
    "                  'max_iter': [2000],\n",
    "                  'batch_size': [64],\n",
    "                  'learning_rate_init': [0.005],\n",
    "                  'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 250, 500, 750, 1000]\n",
    "} \n",
    "\n",
    "\n",
    "param_mlp_grid = ParameterGrid(param_mlp_dict)\n",
    "\n",
    "nn, nn_best_model_idx, nn_train_cv_score, nn_val_cv_score, nn_cv_report_df = mle_tscv.time_series_CV_grid_search(model=nn,\n",
    "                                                                      param_grid=param_mlp_grid,\n",
    "                                                                      cv_splits=splits,  min_train_len=2*365,\n",
    "                                                                      X=X_train,\n",
    "                                                                      y=y_train.values,\n",
    "                                                                      refit=True, dev=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean cross validation score does not improve, remember that in this dataset, overfitting is risky, because there are many features. Moreover, scikit-learn Neural Net implementation does not provide many regularizing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"p_nn\"] = np.concatenate((nn.predict(X_train), nn.predict(X_test)),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest: Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best candidates of non-parametric models are Decission treess ensembles. There are two main ensembles:\n",
    "* Random forest (RFs)\n",
    "* Gradient boosting trees (GBMs)\n",
    "\n",
    "A randon forest fits several independent decision trees performing a technique bagging (boostrap aggregating). It basically samples observations and features in order to obtain a set of non correlated trees\n",
    "Whereas GBMs fits trees sequentially to residuals, so it continuously improves predicion until it starts to overfit. A concrete (and very powerfull) implementation of GBMs is called eXtreme Gradient Boosting machines (XGBs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=300, criterion = \"mse\", max_features = \"sqrt\", bootstrap =True, oob_score = True, n_jobs=-1, random_state = 123,  verbose=False)\n",
    "\n",
    "\n",
    "param_rf_dict = {'max_depth':[3, 5, 10, 15, 20 ,25],\n",
    "                  'min_samples_split': [5,10,25],\n",
    "                  'min_samples_leaf': [5,10, 25]} \n",
    "param_rf_grid = ParameterGrid(param_rf_dict)\n",
    "\n",
    "\n",
    "rf, rf_best_model_idx, rf_train_cv_score, rf_val_cv_score, rf_cv_report_df= mle_tscv.time_series_CV_grid_search(model=rf,\n",
    "                                                                      param_grid=param_rf_grid,\n",
    "                                                                      cv_splits=splits,  min_train_len=2*365,\n",
    "                                                                      X=X_train,\n",
    "                                                                      y=y_train.values,\n",
    "                                                                      refit=True, dev=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"p_rf\"] = np.concatenate((rf.predict(X_train), rf.predict(X_test)),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest yields a good result, but it does not improve lasso regression results, however it also provides an insigth of feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_features_imp = rf.feature_importances_\n",
    "rf_feat_imp_df = pd.DataFrame(index=features, data=rf_features_imp, columns=[\"importante\"]).sort_values(by=\"importante\")\n",
    "rf_feat_imp_df.head(10).plot(kind=\"barh\")\n",
    "plt.title(\"Top 10 most important features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB: Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'colsample_bytree': [0.6],\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [2, 3, 5],\n",
    "    \"lambda\" : [100, 50, 10, 1, 0.1], \"alpha\": [0.0],\n",
    "    \"eta\": [0.1, 0.01]\n",
    "}\n",
    "\n",
    "# Instantiate the regressor: gbm\n",
    "xgb = xgb.XGBRegressor(random_state=123, n_jobs =-1, objective=\"reg:linear\")\n",
    "\n",
    "param_xgb_grid = ParameterGrid(xgb_params)\n",
    "\n",
    "\n",
    "xgb, xgb_best_model_idx, xgb_train_cv_score, xgb_val_cv_score, xgb_cv_report_df= mle_tscv.time_series_CV_grid_search(model=xgb,\n",
    "                                                                      param_grid=param_xgb_grid,\n",
    "                                                                      cv_splits=splits,  min_train_len=2*365,\n",
    "                                                                      X=X_train,\n",
    "                                                                      y=y_train.values,\n",
    "                                                                      refit=True, dev=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"p_xgb\"] = np.concatenate((xgb.predict(X_train), xgb.predict(X_test)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"e_xgb\"] = preds_df[\"target_spot_price_t1\"]-preds_df[\"p_xgb\"]\n",
    "preds_df[\"e_abs_xgb\"] = abs(preds_df[\"e_xgb\"])\n",
    "preds_df[\"e_abs_pct_xgb\"] = preds_df[\"e_abs_xgb\"]/preds_df[\"target_spot_price_t1\"]\n",
    "preds_df.groupby(\"flg_isTrain\")[\"e_abs_pct_xgb\"].mean().to_frame(\"MAPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train, RMSE_train, MAPE_train, R2_train = mle_preds.pred_and_score_model(model=xgb, X=X_train, y=y_train, label=\"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test, RMSE_test, MAPE_test, R2_test = mle_preds.pred_and_score_model(model=xgb, X=X_test, y=y_test, label=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, XGB improves lasso regression results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection and residual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"lr\", \"lasso\", \"nn\", \"rf\", \"xgb\"]\n",
    "xval_report_df = pd.DataFrame(index=models, \n",
    "             data={\"train\": [lr_cv_mean_train_score,\n",
    "                             lasso_train_cv_score[xgb_best_model_idx],\n",
    "                             nn_train_cv_score[xgb_best_model_idx],\n",
    "                             rf_train_cv_score[xgb_best_model_idx],\n",
    "                             xgb_train_cv_score[xgb_best_model_idx]],\n",
    "                  \"val\": [lr_cv_mean_val_score,\n",
    "                          lasso_val_cv_score[xgb_best_model_idx],\n",
    "                          nn_val_cv_score[xgb_best_model_idx],\n",
    "                          rf_val_cv_score[xgb_best_model_idx],\n",
    "                          xgb_val_cv_score[xgb_best_model_idx]]}\n",
    "            )\n",
    "\n",
    "xval_report_df.sort_values(by=\"val\", ascending=False, inplace=True)\n",
    "x_tickers = xval_report_df.index.values\n",
    "y_values = xval_report_df[\"val\"].values\n",
    "barplot = plt.bar(x_tickers, y_values)\n",
    "barplot[-1].set_color(\"r\")\n",
    "plt.title(\"Model cross validation assessment\")\n",
    "plt.ylabel(\"Mean x-val RMSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be clearly seen that xgb is the best model, due to its low x-val average RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train =  xgb.predict(X_train)\n",
    "p_test = xgb.predict(X_test)\n",
    "mle_preds.plot_predictions(y=y_test, p=p_test, time_index=idx_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though model performance is pretty good, when looking at residual analysis, two flaws can be detected:\n",
    "* Residuals are left skewed\n",
    "* Residuals variance over time is constant, but plotted against actual values, when spot price is low, the model tends to under predict. \n",
    "\n",
    "To further improve prediction accuracy, it is suggested to analyze if this issue is due to weekend effect and add a flag that models it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Ensemble: Weighted Average\n",
    "\n",
    "The easiest way to combine predictions is to average model forecast weighting by x-val score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 1/xval_report_df.loc[[\"xgb\", \"lr\"], \"val\"]\n",
    "w = w/w.sum()\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"p_ens\"] = (preds_df[\"p_xgb\"]*w[\"xgb\"] + preds_df[\"p_lasso\"]*w[\"lr\"])/w.sum()\n",
    "preds_df[\"r_ens\"] = (preds_df[\"target_spot_price_t1\"] - preds_df[\"p_ens\"])**2\n",
    "preds_df.groupby(\"flg_isTrain\")[\"r_ens\"].mean().apply(np.sqrt).to_frame(\"Ensemble Test RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"r_xgb\"] = (preds_df[\"target_spot_price_t1\"] - preds_df[\"p_xgb\"])**2\n",
    "preds_df.groupby(\"flg_isTrain\")[\"r_xgb\"].mean().apply(np.sqrt).to_frame(\"XGB Test RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This basic ensembling strategy does not improve results over XGB model, but it ilustrates a general approach to further improve forecasting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgb, open(DEPLOY_PATH + DEPLOY_MODEL_NAME, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lrt ./models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
